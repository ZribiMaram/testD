{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./detection_tunisian_food\\valid\\recipe_image_9_12_jpg.rf.00629e519f18860ec5413901ae60ef0e.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\images-5-_jpeg.rf.05d093ba9376b96ca452f3b165876f0a.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\recipe_image_14_15_jpg.rf.30189aea4fad1c2b80c3438b73fbffd4.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\Baklawa-facile_jpg.rf.3d974c3e09ab69cc774a0c7534a8e78b.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\recipe_image_9_96_jpg.rf.8e24cdbde809dee8e5c6451b5dd247cb.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\recipe_image_9_96_jpg.rf.8e24cdbde809dee8e5c6451b5dd247cb.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\6_jpeg.rf.9249ca9bba69f9228529d829097259ab.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\frecasee_jpeg.rf.9dba78161833e1474410e00e7a370134.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\498382_jpg.rf.a5638d372dc69d7f3a9ba3c778becce2.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\498382_jpg.rf.a5638d372dc69d7f3a9ba3c778becce2.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\recipe_image_29_16_jpg.rf.cb06b7ec6a25c8a7a02e2821164c86c1.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\53_jpg.rf.cb4533cd5a3c6b9f52d7eec63417700f.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\34_jpg.rf.d62dd6ff37fc9806076063a377c50624.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\34_jpg.rf.d62dd6ff37fc9806076063a377c50624.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\70_jpeg.rf.d24d9a81e4e4a55b948261f713f2bff0.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\22_jpeg.rf.e00cf2c17cfa72f85c9e91c7ef94d277.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\22_jpeg.rf.e00cf2c17cfa72f85c9e91c7ef94d277.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\13_jpeg.rf.dfacba01b20661a728f055a06792ec02.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\88_jpg.rf.d849c81bcbbb6ac70d17fe4663794442.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\26_jpeg.rf.fe1e94c19cd5004483a21a6c6dd81161.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\26_jpeg.rf.fe1e94c19cd5004483a21a6c6dd81161.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\26_jpeg.rf.fe1e94c19cd5004483a21a6c6dd81161.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\recipe_image_13_18_jpg.rf.f890700cfebc876b01ba9ff2569821eb.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\54_jpg.rf.f7b417e4cfbbbbdd537471db11d8cdf5.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\54_jpg.rf.f7b417e4cfbbbbdd537471db11d8cdf5.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\54_jpg.rf.f7b417e4cfbbbbdd537471db11d8cdf5.jpg\n",
      "File not found: ./detection_tunisian_food\\valid\\54_jpg.rf.f7b417e4cfbbbbdd537471db11d8cdf5.jpg\n",
      "Images have been organized into class folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "base_dir = './detection_tunisian_food'\n",
    "csv_file = os.path.join(base_dir, '_annotations.csv')\n",
    "image_dir = os.path.join(base_dir, 'valid')  # Assuming images are in 'test'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('./detection_tunisian_food/valid/_annotations.csv')\n",
    "\n",
    "\n",
    "# Create directories for each class\n",
    "class_names = df['class'].unique()\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "# Move images to respective class folders\n",
    "for _, row in df.iterrows():\n",
    "    filename = row['filename']\n",
    "    class_name = row['class']\n",
    "    src_path = os.path.join(image_dir, filename)\n",
    "    dest_path = os.path.join(base_dir, class_name, filename)\n",
    "    \n",
    "    # Check if the file exists before moving\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.move(src_path, dest_path)\n",
    "    else:\n",
    "        print(f\"File not found: {src_path}\")\n",
    "\n",
    "print(\"Images have been organized into class folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m test_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_dir, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Générateurs de données avec augmentation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      9\u001b[0m     rescale\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m     10\u001b[0m     rotation_range\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[0;32m     11\u001b[0m     width_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m     12\u001b[0m     height_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m     13\u001b[0m     shear_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m     14\u001b[0m     zoom_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m     15\u001b[0m     horizontal_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m     fill_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m valid_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\n\u001b[0;32m     20\u001b[0m test_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "train_dir = './detection_tunisian_food/train'\n",
    "valid_dir = './detection_tunisian_food/valid'\n",
    "test_dir = './detection_tunisian_food/test'\n",
    "\n",
    "# Image dimensions\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# Définir les chemins\n",
    "base_dir = './detection_tunisian_food'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Générateurs de données avec augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Créer les générateurs\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(\n",
    "    valid_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32, \n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle MobileNetV2\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3), \n",
    "    include_top=False, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Geler les couches convolutives\n",
    "base_model.trainable = False\n",
    "\n",
    "# Ajouter une tête de classification personnalisée\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Afficher le résumé\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner uniquement les couches ajoutées\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_steps=len(valid_data),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Débloquer les couches supérieures de MobileNetV2\n",
    "base_model.trainable = True\n",
    "\n",
    "# Régler un taux d'apprentissage réduit\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tuning\n",
    "fine_tune_history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_steps=len(valid_data),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer sur le set de test\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save('tunisian_food_mobilenetv2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes de précision\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Courbes de perte\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
